TASK 1: 

1️⃣ Python Clarity:

What i focues on:

With context to project I routed myself to just focusing on python in context to files, pdfs not concepts like OOP, Class or complex data structres.

What i did:

scripts/read-files.py contains basic file handling stuff which is done by using data/sample.txt as a data.
What have i learnt:
A quick refresh to my file handling knowledge
Refresh to string handling and regex
Learnt the usage of shutil
Learnt about unicode escape issues 
Referred mostly from GeeksforGeeks for help and task is generated by ChatGPT


TASK 2:

2️⃣ Data & Metadata Basics:

What i focused on:

I focused on understanding what kind of data that we were going to handle and how to metadata those.

What i did:

I read the mentioned atricles(https://www.coursera.org/articles/what-is-metadata, https://www.tessresearch.org/scientific-paper-part-1/, https://www.tessresearch.org/scientific-paper-part-2/) and got few ideas using AI too. 

What i learnt:

Metadata is “data about data” and helps describe what a document is and how to interpret it.
A DOI acts like a permanent, unique identifier for a paper, similar to a digital fingerprint.
Some metadata fields reveal meaning faster — especially title, abstract, and keywords — because they summarize intent before reading the full document.
Created a metadata on the data/sample.pdf and it is present in outputs/manual_metadata.json


TASK3:

3️⃣ Working with PDF & Word Files:

What i foucsed on:

I focused on extracting data from PDFs and Word files, I've used PyMuPDF for PDF extarction and python - docx for extarcting data from word documents.

What i did:

I have uploaded same files:
data/relaistic_extraction_paper.docx and data/relaistic_extraction_paper.pdf 
Basic blank-line splitter (failed on single-newline PDFs).
Inserted blank lines before line-start numbered headings and known headings (improved slightly).
Inserted single newlines before inline numbered headings and known-words (caused uneven fragments).
Collapsed single newlines into spaces inside chunks to fix line wraps.

Root cause: inserting single `\n` before inline headings is not sufficient for the `\n\n+` split step — single newlines remained and collapsing later joined fragments in awkward places.

What i learnt:

Learned to work with PyMuPDF and python docx. 
.spli() - splits whatever escape sequences given in it
.strip() - removes spaces at the beginning and end
.enumerate() - we can iterate 2 things at a time

